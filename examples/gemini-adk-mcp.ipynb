{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Gemini 2.5 with ADK (Agent Development Kit) and MCP (Model Context Protocol) Servers\n",
    "\n",
    "Agent Development Kit (ADK) is a new modular framework for developing and deploying AI agents. ADK makes it easy to get started with simple agents powered by Gemini models and Google AI tools while providing the control and structure needed for more complex agent architectures and orchestration.\n",
    "\n",
    "Gemini models can be used with MCP server using its native tool calling capabilities. MCP, or Model Context Protocol, is an open standard introduced by Anthropic designed to standardize how AI models like Gemini interact with external tools and data sources. Instead of requiring custom integrations for each tool, MCP provides a structured way for models to access context, such as functions (tools), data sources (resources), or pre-defined prompts. This allows AI agents to securely and efficiently connect with real-world systems and workflows.\n",
    "\n",
    "MCP server expose their tools via JSON schema definitions, which can be converted to Gemini compatible OpenAPI schema definitions. This allows you to easily use MCP server with Gemini models, below you will example on how to implement this. \n",
    "\n",
    "You can learn more about Google Search integration with Gemini here:\n",
    "- [https://ai.google.dev/gemini-api/docs/function-calling?lang=python](https://ai.google.dev/gemini-api/docs/function-calling?lang=python&example=weather)\n",
    "- [https://google.github.io/adk-docs/tools/mcp-tools/](https://google.github.io/adk-docs/tools/mcp-tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-adk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philschmid/projects/personal/gemini-samples/.venv/lib/python3.13/site-packages/google/adk/tools/mcp_tool/mcp_tool.py:88: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n",
      "Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call: {'location': 'Berlin, Germany', 'date': '2025-09-21'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x16759e490>\n",
      "Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x1678c4170>, 1055386.773307625)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x16759de50>\n",
      "auth_config or auth_config.auth_scheme is missing. Will skip authentication.Using FunctionTool instead if authentication is not required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function response: {'result': CallToolResult(meta=None, content=[TextContent(type='text', text='{\"2025-09-21T00:00\":20.4,\"2025-09-21T01:00\":19.9,\"2025-09-21T02:00\":19.2,\"2025-09-21T03:00\":18.3,\"2025-09-21T04:00\":18.7,\"2025-09-21T05:00\":18.5,\"2025-09-21T06:00\":17.6,\"2025-09-21T07:00\":18.7,\"2025-09-21T08:00\":20.6,\"2025-09-21T09:00\":23.5,\"2025-09-21T10:00\":25.7,\"2025-09-21T11:00\":26.4,\"2025-09-21T12:00\":26.1,\"2025-09-21T13:00\":24.7,\"2025-09-21T14:00\":24,\"2025-09-21T15:00\":22.4,\"2025-09-21T16:00\":20.8,\"2025-09-21T17:00\":19.6,\"2025-09-21T18:00\":17.7,\"2025-09-21T19:00\":16.9,\"2025-09-21T20:00\":15.8,\"2025-09-21T21:00\":15,\"2025-09-21T22:00\":14.2,\"2025-09-21T23:00\":13.6}', annotations=None, meta=None)], structuredContent=None, isError=False)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x16759e5d0>\n",
      "Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x1678c4470>, 1055389.886287083)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x16759fd90>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the weather forecast for Berlin on 2025-09-21:\n",
      "00:00: 20.4°C\n",
      "01:00: 19.9°C\n",
      "02:00: 19.2°C\n",
      "03:00: 18.3°C\n",
      "04:00: 18.7°C\n",
      "05:00: 18.5°C\n",
      "06:00: 17.6°C\n",
      "07:00: 18.7°C\n",
      "08:00: 20.6°C\n",
      "09:00: 23.5°C\n",
      "10:00: 25.7°C\n",
      "11:00: 26.4°C\n",
      "12:00: 26.1°C\n",
      "13:00: 24.7°C\n",
      "14:00: 24.0°C\n",
      "15:00: 22.4°C\n",
      "16:00: 20.8°C\n",
      "17:00: 19.6°C\n",
      "18:00: 17.7°C\n",
      "19:00: 16.9°C\n",
      "20:00: 15.8°C\n",
      "21:00: 15.0°C\n",
      "22:00: 14.2°C\n",
      "23:00: 13.6°C\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from google.genai import types\n",
    "from google.adk import Agent, Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import McpToolset,StdioConnectionParams, StdioServerParameters\n",
    "\n",
    "async def mcp_agent():\n",
    "        # Step 1: Connect to MCP Server and Get Tools \n",
    "        tools = McpToolset(\n",
    "            connection_params=StdioConnectionParams(\n",
    "                server_params = StdioServerParameters(\n",
    "                    command='npx',\n",
    "                    args=[\n",
    "                        \"-y\",  # Argument for npx to auto-confirm install\n",
    "                        \"@philschmid/weather-mcp\",\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        # Step 2: Define the Agent \n",
    "        root_agent = Agent(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            name='weather_assistant',\n",
    "            instruction='Can read the weather in a specific city',\n",
    "            tools=[tools], \n",
    "        )\n",
    "\n",
    "        # Step 3: Setup Session, Runner, and Execute \n",
    "        session_service = InMemorySessionService()\n",
    "        session = await session_service.create_session(app_name='weather_app', user_id='john', session_id=\"s-john\")\n",
    "        runner = Runner(agent=root_agent, app_name='weather_app', session_service=session_service)\n",
    "\n",
    "        # Runner is responsible for executing the agent\n",
    "        runner = Runner(\n",
    "            app_name='weather_app',\n",
    "            agent=root_agent,\n",
    "            session_service=session_service,\n",
    "        )\n",
    "\n",
    "        # Step 4: Run the agent \n",
    "        prompt = f\"What is the weather in Berlin tomorrow, {datetime.now().strftime('%Y-%m-%d')}?\"\n",
    "        user_content = types.Content(role='user', parts=[types.Part(text=prompt)])\n",
    "\n",
    "        events_async = runner.run_async(\n",
    "            session_id=session.id, user_id=session.user_id, new_message=user_content\n",
    "        )\n",
    "\n",
    "        async for event in events_async:\n",
    "            if event.content.parts[0].function_call:\n",
    "                print(f\"Function call: {event.content.parts[0].function_call.args}\")\n",
    "            elif event.content.parts[0].function_response:\n",
    "                print(f\"Function response: {event.content.parts[0].function_response.response}\")\n",
    "            else:\n",
    "                print(event.content.parts[0].text)\n",
    "                \n",
    "await mcp_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
